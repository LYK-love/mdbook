# Chatgpt

> And therein lies the secret to the illusion, for illusion is what it is. The “intelligence” lies with us, not the computer program we are interacting with. As has been the case since the start of AI, what those systems do when we interact with them is provide not ***AI\*** but ***IA\*** – *intelligence augmentation*. (Autonomous AI systems are something else; that’s a whole separate topic.) Once you realize that, it seems clear that the initial fear of mathematics educators that such packages will make is super easy for students to cheat the system by simply asking ChatGPT to answer their homework questions for them, is simply not justified.



> The point is, a LLM like ChatGPT generates text by predicting the most likely next character (or word, or whatever unit of language the system designer chooses), based on a search of a large corpus of text. There is no notion of truth or accuracy built in. It really is just a form of auto-complete. 
>
> That approach guarantees the result will be fluent text. It also means that a lot of the time the output you get will be correct, since the bulk of the texts in the large search corpus ChatGPT has access to (and was trained on) will surely be correct. But since the LLM operates at the level of syntax, you’re never going to get an output you can be sure is correct. We users have to provide the required reality check. So a teacher need not fear that a novice will be able to ace the homework assignment by copy-pasting from ChatGPT. (English and history teachers have more of a problem.)



https://www.mathvalues.org/masterblog/chatgpt-for-mathematicians-a-tool-in-search-of-good-applications



一个例子:

即使对于最基本的逻辑判断任务, ChatGPT依然能生成错误的回答(下图的中文版问答). 更令人震惊的是, 中文版回答虽然是错的, 但英文版却是错的. 

![](./assets/ChatGPT-answer.png)